{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "iP6YBwZg2s83"
      ],
      "authorship_tag": "ABX9TyNcQnvD7sx0LpL4AOw9CT6y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BothRocks/maquinito-17/blob/main/Maquinito%2017%20-%20Safari%20Sonoro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Maquinito 17 - Safari Sonoro"
      ],
      "metadata": {
        "id": "QaoVwIo42jhT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carga de librerías, importación de datos, preparación del sistema"
      ],
      "metadata": {
        "id": "iP6YBwZg2s83"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output, HTML\n",
        "!pip install --quiet --upgrade git+https://github.com/huggingface/diffusers.git git+https://github.com/huggingface/transformers.git accelerate\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "wNxP438iefmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_TkjBh5qJPw"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "import seaborn as sns\n",
        "import torch\n",
        "\n",
        "from diffusers import AudioLDM2Pipeline, DPMSolverMultistepScheduler\n",
        "from google.colab import files\n",
        "from IPython.display import Audio\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from transformers import AutoProcessor, Kosmos2ForConditionalGeneration, pipeline\n",
        "\n",
        "%config InlineBackend.figure_format = 'retina'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_text_name = \"microsoft/kosmos-2-patch14-224\"\n",
        "model_audio_name = \"cvssp/audioldm2\"\n",
        "\n",
        "model_text = Kosmos2ForConditionalGeneration.from_pretrained(model_text_name)\n",
        "processor_text = AutoProcessor.from_pretrained(model_text_name)\n",
        "clear_output()\n",
        "\n",
        "pipe_audio = AudioLDM2Pipeline.from_pretrained(model_audio_name, torch_dtype=torch.float16)\n",
        "pipe_audio.scheduler = DPMSolverMultistepScheduler.from_config(pipe_audio.scheduler.config)\n",
        "pipe_audio.to(\"cuda\")\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "ltO4ErjR1s3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def image_with_boxes(original_image, entities):\n",
        "\n",
        "  image_with_boxes = original_image.copy()\n",
        "  draw = ImageDraw.Draw(image_with_boxes)\n",
        "\n",
        "  # Image dimensions\n",
        "  width, height = image.size\n",
        "\n",
        "  colors_back = ['#425bde', '#bd92ea', '#ffdbff', '#f590bc', '#de425b']\n",
        "  colors_fore = ['#ffffff', '#ffffff', '#000000', '#ffffff', '#ffffff']\n",
        "  line_thickness = 3\n",
        "  font = ImageFont.truetype(\"LiberationSans-Regular.ttf\", 12)\n",
        "\n",
        "\n",
        "  for index, (entity, boxes) in enumerate(entities):\n",
        "      color_back = colors_back[index % len(colors_back)]\n",
        "      color_fore = colors_fore[index % len(colors_fore)]\n",
        "      for box in boxes:\n",
        "\n",
        "          left, top, right, bottom = box\n",
        "          absolute_left = left * width\n",
        "          absolute_top = top * height\n",
        "          absolute_right = right * width\n",
        "          absolute_bottom = bottom * height\n",
        "          draw.rectangle([absolute_left, absolute_top, absolute_right, absolute_bottom], outline=color_back, width=line_thickness)\n",
        "\n",
        "          _,_,text_width, text_height = draw.textbbox((0,0), entity, font=font)\n",
        "          background_top_left_x = absolute_left\n",
        "          background_top_left_y = absolute_top\n",
        "          background_bottom_right_x = absolute_left + text_width\n",
        "          background_bottom_right_y = absolute_top + text_height\n",
        "\n",
        "          draw.rectangle([background_top_left_x, background_top_left_y, background_bottom_right_x + line_thickness*2, background_bottom_right_y+ line_thickness*2],\n",
        "                               fill=color_back)\n",
        "          draw.text((absolute_left +line_thickness, absolute_top + line_thickness), entity, font=font, fill=color_fore)\n",
        "\n",
        "\n",
        "  sns.set()\n",
        "  fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "  axs[0].imshow(image)\n",
        "  axs[0].axis('off')\n",
        "  axs[0].set_title('Imagen original')\n",
        "\n",
        "  axs[1].imshow(image_with_boxes)\n",
        "  axs[1].axis('off')\n",
        "  axs[1].set_title(caption)\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "qxf9f9joIr6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aquí empieza lo interesante"
      ],
      "metadata": {
        "id": "ypbsx9dkBBta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "image_filename = next(iter(uploaded))\n",
        "image = Image.open(image_filename)\n",
        "image.thumbnail((640, 640))\n",
        "\n",
        "prompt = \"<grounding>\"\n",
        "\n",
        "inputs = processor_text(text=prompt, images=image, return_tensors=\"pt\")\n",
        "\n",
        "generated_ids = model_text.generate(\n",
        "    pixel_values=inputs[\"pixel_values\"],\n",
        "    input_ids=inputs[\"input_ids\"],\n",
        "    attention_mask=inputs[\"attention_mask\"],\n",
        "    image_embeds=None,\n",
        "    image_embeds_position_mask=inputs[\"image_embeds_position_mask\"],\n",
        "    use_cache=True,\n",
        "    max_new_tokens=128,\n",
        ")\n",
        "\n",
        "generated_text = processor_text.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "processed_text = processor_text.post_process_generation(generated_text, cleanup_and_extract=False)\n",
        "caption, entities = processor_text.post_process_generation(generated_text)\n",
        "entities = [(entity[0], entity[2]) for entity in entities]\n",
        "html = f\"<h1>{caption}</h1>\"\n",
        "display(HTML(html))\n",
        "image_with_boxes(image, entities)"
      ],
      "metadata": {
        "id": "mJAaLpfw2QeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = torch.Generator(\"cuda\").manual_seed(1)\n",
        "negative_prompt = \"Low quality, average quality.\"\n",
        "audio = pipe_audio(caption, audio_length_in_s=10.24, negative_prompt=negative_prompt, generator=generator, num_inference_steps=40).audios[0]\n",
        "Audio(audio, rate=16000)"
      ],
      "metadata": {
        "id": "a_Ln2Z-DmNmS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}